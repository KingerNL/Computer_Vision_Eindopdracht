{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data.catalog import DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.join(\"..\\Computer_Vision_Eindopdracht\\deep_learning\") # Go one folder up\n",
    "\n",
    "#dataset \n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, os.path.join(ROOT_DIR, \"train\", \"_annotations.coco.json\"),os.path.join(ROOT_DIR,'train'))\n",
    "register_coco_instances(\"my_dataset_val\", {}, os.path.join(ROOT_DIR,\"valid\", \"_annotations.coco.json\"),os.path.join(ROOT_DIR,'valid'))\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\")\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('deep_learning/output_data_det.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "from custom_config_detectron2 import *\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "white: np.ndarray  = np.array([\"white\",  (210, 210, 210)],   dtype=object)\n",
    "black: np.ndarray  = np.array([\"black\",  (30,  30,  30 )],    dtype=object)\n",
    "metal: np.ndarray  = np.array([\"metal\",  (120, 120, 120)], dtype=object)\n",
    "\n",
    "pink:  np.ndarray  = np.array([\"pink\",   (120, 90,  220)], dtype=object)\n",
    "blue:  np.ndarray  = np.array([\"blue\",   (255, 100 ,10 )],  dtype=object)\n",
    "\n",
    "colors: list = (white, black, metal)\n",
    "\n",
    "lower_background_color = (13,     145,      20)\n",
    "upper_background_color = (35,     255,     255)\n",
    "lower_blue             = (30,     120,      20)\n",
    "upper_blue             = (120,    255,     255)\n",
    "lower_pink             = (130,    50,      20)\n",
    "upper_pink             = (180,    255,     255)\n",
    "\n",
    "im = cv2.imread(\"deep_learning/test/Image_Yellow (201).jpg\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "imgHLS = cv2.cvtColor(im, cv2.COLOR_BGR2HLS)\n",
    "hsv_image = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "mask = outputs['instances'].pred_masks.numpy()\n",
    "\n",
    "mask5 = cv2.inRange(hsv_image, lower_background_color, upper_background_color) #============================================\n",
    "mask_binary = cv2.bitwise_not(mask5) #============================================\n",
    "mask_with_color = cv2.bitwise_and(hsv_image, im, mask = mask_binary) #============================================\n",
    "\n",
    "contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "mask = mask.astype(np.uint8)\n",
    "mask[mask > 0] = 255\n",
    "\n",
    "fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "borderThickness = 2\n",
    "index = 1\n",
    "\n",
    "\n",
    "for i in range(mask.shape[0]):\n",
    "    # Creating threshold of the manually created mask and then finding contours of roadmarks\n",
    "    gray = mask[i,:,:]\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU + cv2.THRESH_BINARY)[1]\n",
    "    contour = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    cntrs = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour = max(contour, key=cv2.contourArea)\n",
    "\n",
    "    mask_binary = cv2.bitwise_not(mask5)\n",
    "    mask_with_color = cv2.bitwise_and(hsv_image, im, mask = mask_binary)\n",
    "    contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for contour in contours:\n",
    "        maskr = np.zeros(im.shape[:2], dtype=\"uint8\")\n",
    "        cv2.drawContours(maskr, [contour], -1, 255, -1)\n",
    "\n",
    "        # check pink\n",
    "        pink_mask = np.zeros(result.shape[:2], dtype=\"uint8\")\n",
    "        cv2.drawContours(pink_mask, [contour], -1, 255, -1)\n",
    "        individual_masks = cv2.bitwise_and(result, result, mask = pink_mask)\n",
    "        pink_mask = cv2.inRange(individual_masks, lower_pink, upper_pink)\n",
    "\n",
    "        if np.mean(pink_mask) > 0:\n",
    "            match_color = 'pink'\n",
    "\n",
    "        mean = cv2.mean(im, mask=maskr)[0:3]\n",
    "        min_rmse = 1000000\n",
    "        # print(mean)\n",
    "        for color in colors:\n",
    "            bb = color[1][0]\n",
    "            gg = color[1][1]\n",
    "            rr = color[1][2]\n",
    "            rmse = sqrt( ( (mean[2]-rr)*(mean[2]-rr) + (mean[1]-gg)*(mean[1]-gg) + (mean[0]-bb)*(mean[0]-bb) )/3 )\n",
    "\n",
    "            if rmse < min_rmse:\n",
    "                min_rmse = rmse\n",
    "                match_color = color[0]\n",
    "    #qprint(match_color)\n",
    "\n",
    "    # Create three channel mask for single part of the roadmark\n",
    "    mask_part = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Count every pixel in mask\n",
    "    pixels = np.sum(gray > 0)\n",
    "\n",
    "    # Combine image and mask to remove noise\n",
    "    result = cv2.bitwise_and(imgHLS, mask_part)\n",
    "    \n",
    "    # cv2.namedWindow(\"Resized_Window\", cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.imshow(\"Resized_Window\", result)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "        \n",
    "# cv2.imwrite(\"deep_learning/results/ouput_img.jpg\",out.get_image()[:, :, ::-1])\n",
    "# cv2.namedWindow(\"Resized_Window\", cv2.WINDOW_KEEPRATIO)\n",
    "# cv2.imshow(\"Resized_Window\", mask[1:])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import glob\n",
    "\n",
    "# get the path/directory\n",
    "TEST_DIR = \"deep_learning/test\"\n",
    "RES_DIR = \"deep_learning/results\"\n",
    "# Counter var for filenames\n",
    "d = 0\n",
    "\n",
    "# Using glob to loop over image dir\n",
    "for images in glob.iglob(f'{TEST_DIR}/*'):\n",
    "    # Collecting all images of type '.jpg'\n",
    "    if images.endswith(\".jpg\"):\n",
    "        # Masking images\n",
    "        im = cv2.imread(images)\n",
    "        outputs = predictor(im)\n",
    "        v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        # Saving files\n",
    "        filename = \"deep_learning/results_2000/classified_img_%d.jpg\"%d\n",
    "        cv2.imwrite(filename, out.get_image()[:, :, ::-1])\n",
    "        d+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"deep_learning/test/Image_Yellow (201).jpg\")\n",
    "imgHLS = cv2.cvtColor(im, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.imshow('mask', out.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "mask_array = outputs['instances'].pred_masks.numpy()\n",
    "classes = outputs['instances'].pred_classes.numpy()\n",
    "#orientation = outputs['instances'].pred_orientation.numpy()\n",
    "print(classes)\n",
    "\n",
    "mask = mask_array.astype(np.uint8)\n",
    "mask[mask > 0] = 255\n",
    "\n",
    "\n",
    "\n",
    "for i in range(mask.shape[0]):\n",
    "    # Creating threshold of the manually created mask and then finding contours of roadmarks\n",
    "    gray = mask[i,:,:]\n",
    "    thresh = cv2.threshold(\n",
    "        gray, 0, 255, cv2.THRESH_OTSU + cv2.THRESH_BINARY)[1]\n",
    "    contour = cv2.findContours(\n",
    "        thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    contour = max(contour, key=cv2.contourArea)\n",
    "\n",
    "    # Create three channel mask for single part of the roadmark\n",
    "    mask_part = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Count every pixel in mask\n",
    "    pixels = np.sum(gray > 0)\n",
    "    \n",
    "\n",
    "result = cv2.bitwise_and(imgHLS, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = outputs['instances'].pred_classes\n",
    "scores = outputs['instances'].scores\n",
    "keypoints = outputs['instances'].pred_boxes\n",
    "classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = classes.cpu().detach().numpy()\n",
    "a = str(a)\n",
    "a = a.replace('0', 'bolt')\n",
    "a = a.replace('1', 'nut')\n",
    "a = a.replace('2', 'ring')\n",
    "a = a.replace('3', 'metal attachment')\n",
    "a = a.replace('4', 'valve')\n",
    "\n",
    "    \n",
    "a\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = outputs['instances'].pred_boxes.tensor.numpy()\n",
    "keypoints\n",
    "# centerx,centery = ( np.average(keypoints[:2]),np.average(keypoints[2:]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORIENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_,_),(_,_),angle = cv.fitEllipse(contour)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = outputs['instances'].pred_masks.numpy()\n",
    "alist = alist[0]\n",
    "alist\n",
    "mask = alist.astype(np.uint8)\n",
    "mask[mask > 0] = 255\n",
    "mask \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "white: np.ndarray  = np.array([\"white\",  (210, 210, 210)],   dtype=object)\n",
    "black: np.ndarray  = np.array([\"black\",  (30,  30,  30 )],    dtype=object)\n",
    "metal: np.ndarray  = np.array([\"metal\",  (120, 120, 120)], dtype=object)\n",
    "\n",
    "pink:  np.ndarray  = np.array([\"pink\",   (120, 90,  220)], dtype=object)\n",
    "blue:  np.ndarray  = np.array([\"blue\",   (255, 100 ,10 )],  dtype=object)\n",
    "\n",
    "colors: list = (white, black, metal)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "mask = np.zeros(original_image.shape[:2], dtype=\"uint8\")\n",
    "cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "\n",
    "# check pink\n",
    "pink_mask = np.zeros(cont_mask.shape[:2], dtype=\"uint8\")\n",
    "cv2.drawContours(pink_mask, [contour], -1, 255, -1)\n",
    "individual_masks = cv2.bitwise_and(cont_mask, cont_mask, mask = pink_mask)\n",
    "pink_mask = cv2.inRange(individual_masks, lower_pink, upper_pink)\n",
    "\n",
    "if np.mean(pink_mask) > 0:\n",
    "    return 'pink'\n",
    "\n",
    "mean = cv2.mean(original_image, mask=mask)[0:3]\n",
    "min_rmse = 1000000\n",
    "# print(mean)\n",
    "for color in colors:\n",
    "    bb = color[1][0]\n",
    "    gg = color[1][1]\n",
    "    rr = color[1][2]\n",
    "    rmse = sqrt( ( (mean[2]-rr)*(mean[2]-rr) + (mean[1]-gg)*(mean[1]-gg) + (mean[0]-bb)*(mean[0]-bb) )/3 )\n",
    "\n",
    "    if rmse < min_rmse:\n",
    "        min_rmse = rmse\n",
    "        match_color = color[0]\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('./output_data_det.csv', 'a', encoding='UTF8', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    for contour in range(len(img.contours)):\n",
    "         csv_writer.writerow((img.name, img.contours[contour].kind_of_object, 1, img.contours[contour].position, img.contours[contour].oriÃ«ntation, img.contours[contour].color))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output_5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:42:03) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6070dd119d51010989febe6d8849961dd6ed448ba4b5a8c6012accc20bdac45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
